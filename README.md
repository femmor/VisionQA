# ğŸ§  VisionQA â€“ AI-Powered UI Accessibility Auditor

> Built with ğŸ’¡ Vision Transformers + LLMs | React + FastAPI | Open Source Dev Tool for the Future

VisionQA is an autonomous AI agent that audits UI designs and frontend screenshots for accessibility issues using state-of-the-art AI models like Vision Transformers (ViT) and GPT-4. It helps developers and designers find WCAG violations and generates actionable suggestions, visually marked on your screenshots.

---

## ğŸš€ Features

- ğŸ” Upload UI screenshots and detect accessibility violations
- ğŸ§  Vision Transformer + LLM powered issue identification
- ğŸ“– WCAG-based suggestions via RAG (Retrieval-Augmented Generation)
- ğŸ¯ Visual annotations of UI problems (contrast, alt-text, focus order, etc.)
- ğŸ“„ One-click PDF report generation
- ğŸŒ Modern UI built with React, ShadCn + TailwindCSS

---

## ğŸ› ï¸ Tech Stack

| Layer         | Tech                                        |
| ------------- | ------------------------------------------- |
| Frontend      | React, TypeScript, ShadCn, TailwindCSS      |
| Backend       | FastAPI (Python)                            |
| AI Models     | HuggingFace ViT, OpenAI GPT-4, LangChain    |
| Data Handling | Python PIL, base64, PDFKit                  |
| Deployment    | Vercel (Frontend), Railway/Render (Backend) |

---

## ğŸ§ª Getting Started

### Prerequisites

- Node.js 18+
- Python 3.9+
- OpenAI API Key
- Hugging Face token (optional)
- Pinecone/Weaviate key (if using RAG)

### Frontend Setup

```bash
cd frontend
npm install
npm run dev

```

### ğŸ“£ Contributing

We welcome PRs, ideas, and issues!

Fork the repo

Create a new branch (git checkout -b feature/my-feature)

Commit changes (git commit -am 'Add something')

Push (git push origin feature/my-feature)

Create a Pull Request
